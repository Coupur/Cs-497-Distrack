{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_name = \"Rdatatable\"\n",
    "repo_name = \"data.table\"\n",
    "\n",
    "reponame_noperiod = repo_name.replace(\".\", \"\")\n",
    "reponame_noperiod = reponame_noperiod.replace(\"_\", \"\")\n",
    "reponame_noperiod = reponame_noperiod.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Github(secret)\n",
    "org = g.get_organization(org_name)\n",
    "repo = org.get_repo(repo_name)\n",
    "g.rate_limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pull Request file exist\n",
      "Pull Request Comments file exist\n",
      "Issues Request file exists\n",
      "Issues Request Comments file exists\n"
     ]
    }
   ],
   "source": [
    "file_path_comments = f'Files/{org_name.lower()}_{reponame_noperiod}_pull_request_comments.xlsx'\n",
    "\n",
    "file_path = f'Files/{org_name.lower()}_{reponame_noperiod}_pull_requests.xlsx'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    pull_df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    print(\"Pull Request file exist\")\n",
    "else:\n",
    "    pull_df = pd.DataFrame()\n",
    "    print(\"Error:Pull Request file does not exist \", file_path)\n",
    "\n",
    "if os.path.exists(file_path_comments):\n",
    "    pull_df_comments = pd.read_excel(file_path_comments, engine='openpyxl')\n",
    "    print(\"Pull Request Comments file exist\")\n",
    "else:\n",
    "    pull_df_comments = pd.DataFrame()\n",
    "    print(\"Error:Pull Request Comments file does not exist \",file_path_comments)\n",
    "\n",
    "# Define the file path\n",
    "file_path_comments = f'Files/{org_name.lower()}_{reponame_noperiod}_issues_comments.xlsx'\n",
    "\n",
    "file_path = f'Files/{org_name.lower()}_{reponame_noperiod}_issues.xlsx'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    issues_df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    print(\"Issues Request file exists\")\n",
    "else:\n",
    "    issues_df = pd.DataFrame()\n",
    "    print(\"Error: Issues Request file does not exist \", file_path )\n",
    "if os.path.exists(file_path_comments):\n",
    "    issues_df_comments = pd.read_excel(file_path_comments, engine='openpyxl')\n",
    "    print(\"Issues Request Comments file exists\")\n",
    "else:\n",
    "    issues_df_comments = pd.DataFrame()\n",
    "    print(\"Error: Issues Comments file does not exist \", file_path_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_timestamps(df, column_name='created_at', new_column_name='time'):\n",
    "    \"\"\"\n",
    "    Convert timestamps in a DataFrame column to London time (GMT/UTC+0).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the timestamp column\n",
    "    column_name : str\n",
    "        Name of the column containing timestamps with timezone info\n",
    "    new_column_name : str\n",
    "        Name of the new column to store London time\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with the new London time column added\n",
    "    \"\"\"\n",
    "    # Make sure timestamps are parsed as datetime with timezone info\n",
    "    df[column_name] = pd.to_datetime(df[column_name], utc=True)\n",
    "    \n",
    "    # Convert to London time\n",
    "    london_tz = pytz.timezone('Europe/London')\n",
    "    df[new_column_name] = df[column_name].dt.tz_convert(london_tz)\n",
    "    \n",
    "    # Create a datetime column without timezone info for plotting\n",
    "    df[f'{new_column_name}_naive'] = df[new_column_name].dt.tz_localize(None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "pull_df=standardize_timestamps(pull_df)\n",
    "pull_df_comments=standardize_timestamps(pull_df_comments)\n",
    "issues_df=standardize_timestamps(issues_df)\n",
    "issues_df_comments=standardize_timestamps(issues_df_comments)\n",
    "\n",
    "#get rid of created_at columns\n",
    "pull_df.drop(columns=['created_at'], inplace=True)\n",
    "pull_df_comments.drop(columns=['created_at'], inplace=True)\n",
    "issues_df.drop(columns=['created_at'], inplace=True)\n",
    "issues_df_comments.drop(columns=['created_at'], inplace=True)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_df['created_by'] = pull_df['created_by'].apply(lambda x: x.split('/')[-1])\n",
    "issues_df['created_by'] = issues_df['created_by'].apply(lambda x: x.split('/')[-1])\n",
    "pull_df_comments['created_by'] = pull_df_comments['created_by'].apply(lambda x: re.search(r'login=\"([^\"]+)\"', x).group(1))\n",
    "issues_df_comments['created_by'] = issues_df_comments['created_by'].apply(lambda x: re.search(r'login=\"([^\"]+)\"', x).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fliter out users that have only contributed once across files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# make copies of all the dataframes\n",
    "pull_df_all = pull_df.copy()\n",
    "pull_df_comments_all = pull_df_comments.copy()\n",
    "issues_df_all = issues_df.copy()\n",
    "issues_df_comments_all = issues_df_comments.copy()\n",
    "#drop \"Unnamed: 0\", issue_id, id, body from the comments dataframes\n",
    "issues_df_comments_all.drop(columns=['Unnamed: 0', 'issue_id', 'id', 'body'], inplace=True)\n",
    "pull_df_comments_all.drop(columns=['Unnamed: 0', 'pull_request_id', 'id', 'body'], inplace=True)\n",
    "issues_df_all.drop(columns=['Unnamed: 0', 'id', 'title','closed_at','labels','closed_by'], inplace=True)\n",
    "pull_df_all.drop(columns=['Unnamed: 0', 'id', 'title','closed_at','labels','state','number_commits','number_files_modified','mergeable_status'], inplace=True)\n",
    "#add all the dataframes together making one long file. add one more colum to say if the row was added from the issues or pull requests\n",
    "pull_df_all['type'] = 'pull'\n",
    "issues_df_all['type'] = 'issue'\n",
    "pull_df_comments_all['type'] = 'pull'\n",
    "issues_df_comments_all['type'] = 'issue'\n",
    "\n",
    "#add all the dataframes together making one long file. add one more colum to say if the row was added from the issues or pull requests\n",
    "all_df = pd.concat([pull_df_all, issues_df_all,pull_df_comments_all,issues_df_comments_all])\n",
    "\n",
    "def calculate_user_metrics_all(df, user_column='created_by', type_column='type'):\n",
    "    user_metrics = df.groupby([user_column]).size().reset_index(name='total_activity')\n",
    "    user_metrics['active_days'] = df.groupby([user_column])['time_naive'].nunique().values\n",
    "    \n",
    "    return user_metrics\n",
    "\n",
    "# Calculate user metrics for all_df\n",
    "all_user_metrics = calculate_user_metrics_all(all_df, user_column='created_by', type_column='type')\n",
    "\n",
    "# if a user has only 1 active day and less than 5 total activitys drop them.\n",
    "all_user_metrics = all_user_metrics[(all_user_metrics['active_days'] > 1) | (all_user_metrics['total_activity'] > 5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions to make new data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_daily_activity(df, user_column='created_by', timestamp_column='time_naive'):\n",
    "    \"\"\"\n",
    "    Aggregate timestamp data into daily activity counts per user.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the user and timestamp columns\n",
    "    user_column : str\n",
    "        Name of the column containing user identifiers\n",
    "    timestamp_column : str\n",
    "        Name of the column containing timestamps\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with daily activity counts per user\n",
    "    \"\"\"\n",
    "    # Ensure the timestamp column is in datetime format\n",
    "    df[timestamp_column] = pd.to_datetime(df[timestamp_column], utc=True)\n",
    "    \n",
    "    # Extract date from timestamp\n",
    "    df['date'] = df[timestamp_column].dt.date\n",
    "    \n",
    "    # Aggregate daily activity counts per user\n",
    "    daily_activity = df.groupby([user_column, 'date']).size().reset_index(name='activity_count')\n",
    "    \n",
    "    return daily_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_user_metrics(daily_activity, user_column='created_by'):\n",
    "    \"\"\"\n",
    "    Calculate useful metrics about each user's participation patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    daily_activity : pandas.DataFrame\n",
    "        DataFrame with daily activity counts per user\n",
    "    user_column : str\n",
    "        Name of the column containing user identifiers\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with user metrics\n",
    "    \"\"\"\n",
    "    user_metrics = daily_activity.groupby(user_column)['activity_count'].agg(\n",
    "        total_activity='sum',\n",
    "        mean_activity='mean',\n",
    "        std_activity='std',\n",
    "        min_activity='min',\n",
    "        max_activity='max',\n",
    "        active_days='count' ).reset_index()\n",
    "    \n",
    "    return user_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def create_user_activity_matrix(daily_activity, user_column='created_by', date_column='date'):\n",
    "    \"\"\"\n",
    "    Create a matrix suitable for machine learning.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    daily_activity : pandas.DataFrame\n",
    "        DataFrame with daily activity counts per user\n",
    "    user_column : str\n",
    "        Name of the column containing user identifiers\n",
    "    date_column : str\n",
    "        Name of the column containing dates\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        User activity matrix\n",
    "    \"\"\"\n",
    "    user_activity_matrix = daily_activity.pivot(index=user_column, columns=date_column, values='activity_count').fillna(0)\n",
    "    \n",
    "    return user_activity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate daily activity for pull requests, pull request comments, issues, and issue comments\n",
    "pull_daily_activity = aggregate_daily_activity(pull_df, user_column='created_by', timestamp_column='time_naive')\n",
    "pull_comments_daily_activity = aggregate_daily_activity(pull_df_comments, user_column='created_by', timestamp_column='time_naive')\n",
    "issues_daily_activity = aggregate_daily_activity(issues_df, user_column='created_by', timestamp_column='time_naive')\n",
    "issues_comments_daily_activity = aggregate_daily_activity(issues_df_comments, user_column='created_by', timestamp_column='time_naive')\n",
    "\n",
    "\n",
    "# Calculate user metrics for each type of activity\n",
    "pull_user_metrics = calculate_user_metrics(pull_daily_activity, user_column='created_by')\n",
    "pull_comments_user_metrics = calculate_user_metrics(pull_comments_daily_activity, user_column='created_by')\n",
    "issues_user_metrics = calculate_user_metrics(issues_daily_activity, user_column='created_by')\n",
    "issues_comments_user_metrics = calculate_user_metrics(issues_comments_daily_activity, user_column='created_by')\n",
    "\n",
    "# Create user activity matrices for each type of activity\n",
    "pull_user_activity_matrix = create_user_activity_matrix(pull_daily_activity, user_column='created_by', date_column='date')\n",
    "pull_comments_user_activity_matrix = create_user_activity_matrix(pull_comments_daily_activity, user_column='created_by', date_column='date')\n",
    "issues_user_activity_matrix = create_user_activity_matrix(issues_daily_activity, user_column='created_by', date_column='date')\n",
    "issues_comments_user_activity_matrix = create_user_activity_matrix(issues_comments_daily_activity, user_column='created_by', date_column='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (\n",
    "    pull_daily_activity\n",
    "    .merge(pull_comments_daily_activity, on=['date', 'created_by'], how='outer', suffixes=('_pulls', '_pull_comments'))\n",
    "    .merge(issues_daily_activity, on=['date', 'created_by'], how='outer')\n",
    "    .merge(issues_comments_daily_activity, on=['date', 'created_by'], how='outer', suffixes=('_issues', '_issues_comments'))\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 since some users may not have activity in all categories\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# Ensure all activity columns are integers\n",
    "activity_columns = [col for col in merged_df.columns if col.startswith('activity_count')]\n",
    "merged_df[activity_columns] = merged_df[activity_columns].astype(int)\n",
    "# Get the list of users in all_user_metrics\n",
    "valid_users = all_user_metrics['created_by'].tolist()\n",
    "\n",
    "# Filter merged_df to keep only rows with users in valid_users\n",
    "merged_df = merged_df[merged_df['created_by'].isin(valid_users)]\n",
    "\n",
    "#deleat row 1\n",
    "merged_df = merged_df.drop(merged_df.index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_by</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_count_pulls</th>\n",
       "      <th>activity_count_pull_comments</th>\n",
       "      <th>activity_count_issues</th>\n",
       "      <th>activity_count_issues_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arunsrinivasan</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fedyakov</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geneorama</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juancentro</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arunsrinivasan</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>codecov[bot]</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>dkutner</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>github-actions[bot]</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>iagogv3</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12654</th>\n",
       "      <td>venom1204</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11968 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_by        date  activity_count_pulls  \\\n",
       "1           arunsrinivasan  2014-06-09                     0   \n",
       "2                 fedyakov  2014-06-09                     0   \n",
       "3                geneorama  2014-06-09                     0   \n",
       "4               juancentro  2014-06-09                     0   \n",
       "5           arunsrinivasan  2014-06-10                     0   \n",
       "...                    ...         ...                   ...   \n",
       "12650         codecov[bot]  2025-02-07                     0   \n",
       "12651              dkutner  2025-02-07                     0   \n",
       "12652  github-actions[bot]  2025-02-07                     0   \n",
       "12653              iagogv3  2025-02-07                     0   \n",
       "12654            venom1204  2025-02-07                     1   \n",
       "\n",
       "       activity_count_pull_comments  activity_count_issues  \\\n",
       "1                                 0                      0   \n",
       "2                                 0                      1   \n",
       "3                                 0                      1   \n",
       "4                                 0                      1   \n",
       "5                                 0                      0   \n",
       "...                             ...                    ...   \n",
       "12650                             0                      0   \n",
       "12651                             0                      0   \n",
       "12652                             0                      0   \n",
       "12653                             0                      2   \n",
       "12654                             0                      1   \n",
       "\n",
       "       activity_count_issues_comments  \n",
       "1                                   2  \n",
       "2                                   1  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "5                                   2  \n",
       "...                               ...  \n",
       "12650                               2  \n",
       "12651                               4  \n",
       "12652                               1  \n",
       "12653                               1  \n",
       "12654                               1  \n",
       "\n",
       "[11968 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i wanna try to have the users old data to be used as their trai data and their test be the r data table we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS485",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
