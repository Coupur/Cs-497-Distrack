{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modle Building \n",
    "## Predictive modleing of Git Hub Pulls and Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import scipy.stats as stats\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "#model building\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve, mean_absolute_error, accuracy_score\n",
    "import shap\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_name = \"Rdatatable\"\n",
    "repo_name = \"data.table\"\n",
    "\n",
    "reponame_noperiod = repo_name.replace(\".\", \"\")\n",
    "reponame_noperiod = reponame_noperiod.replace(\"_\", \"\")\n",
    "reponame_noperiod = reponame_noperiod.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2614, 5000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret = \"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\"\n",
    "g = Github(secret)\n",
    "org = g.get_organization(org_name)\n",
    "repo = org.get_repo(repo_name)\n",
    "g.rate_limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files from Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI Interactions Pulls sucsefully loaded\n",
      "CLI Interactions file sucsefully loaded\n"
     ]
    }
   ],
   "source": [
    "#load cli_interactions_pulls\n",
    "#load cli_interactions \n",
    "file_path = f'cli_interactions_pulls.xlsx'\n",
    "if os.path.exists(file_path):\n",
    "    cli_interactions_pulls = pd.read_excel(file_path, engine='openpyxl')\n",
    "    print(\"CLI Interactions Pulls sucsefully loaded\")\n",
    "else:\n",
    "    cli_interactions_pulls = pd.DataFrame()\n",
    "    print(\"Error: CLI Interactions Pulls file does not exist \", file_path)\n",
    "\n",
    "file_path = f'Files/cli_issue_interactions_Small.xlsx'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    cli_interactions = pd.read_excel(file_path, engine='openpyxl')\n",
    "    print(\"CLI Interactions file sucsefully loaded\")\n",
    "else:   \n",
    "    cli_interactions = pd.DataFrame()\n",
    "    print(\"Error: CLI Interactions file does not exist \", file_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def filter_bots(df, column='created_by'):\n",
    "    bot_patterns = r'(?:\\\\[bot\\\\]| bot|dependabot|github-actions|renovate|github|circleci|travis|appveyor|azure|jenkins|ci/cd|snyk|codecov|hdepend|vercel|netlify|heroku|greenkeeper|semantic-release|sonarcloud|probot|lgtm|coveralls)'\n",
    "    return df[~df[column].str.contains(bot_patterns, case=False, na=False)]\n",
    "\n",
    "cli_interactions=filter_bots(cli_interactions, column='created_by')\n",
    "cli_interactions_pulls=filter_bots(cli_interactions_pulls, column='created_by')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepare a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for index, row in df.iterrows():\n",
    "    org_name = row['org']\n",
    "    repo_name = row['repo']\n",
    "    try:\n",
    "        print(f\"Processing {org_name}/{repo_name}...\")\n",
    "        repo = g.get_repo(f\"{org_name}/{repo_name}\")\n",
    "        \n",
    "        # Get all contributors, sorted by number of contributions\n",
    "        contributors = list(repo.get_contributors())\n",
    "        contributors.sort(key=lambda x: x.contributions, reverse=True)\n",
    "        \n",
    "        # Take top contributors (let's say top 10)\n",
    "        top_contributors = contributors[:10]\n",
    "        \n",
    "        # Store their information\n",
    "        for contributor in top_contributors:\n",
    "            results.append({\n",
    "                \"org\": org_name,\n",
    "                \"repo\": repo_name,\n",
    "                \"username\": contributor.login,\n",
    "                \"commits\": contributor.contributions,\n",
    "                \"profile_url\": contributor.html_url\n",
    "            })\n",
    "            \n",
    "        # Avoid rate limiting\n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {org_name}/{repo_name}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_excel(\"top_contributors.xlsx\", index=False)\n",
    "print(\"Top contributors extraction complete! Saved to top_contributors.xlsx.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30% of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users in CLI Interactions:\n",
      "['hadley' 'gaborcsardi' 'jennybc' 'salim-b' 'krlmlr']\n",
      "Users in CLI Interactions Pulls:\n",
      "['jennybc' 'gaborcsardi' 'MichaelChirico' 'rundel' 'krlmlr' 'hadley'\n",
      " 'olivroy' 'salim-b' 'lionel-' 'romainfrancois']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows for each user in the \"created_by\" column for the \"cli_interactions\" dataset and cli_interactions_pulls\n",
    "cli_interactions_user_counts = cli_interactions['created_by'].value_counts()\n",
    "cli_interactions_pulls_user_counts = cli_interactions_pulls['created_by'].value_counts()\n",
    "\n",
    "# Calculate the threshold for the top 20% of users\n",
    "cli_interactions_threshold = int(0.30 * len(cli_interactions_user_counts))\n",
    "cli_interactions_pulls_threshold = int(0.30 * len(cli_interactions_pulls_user_counts))\n",
    "\n",
    "#remove the users who have less than the threshold number of interactions from cli_interactions and cli_interactions_pulls\n",
    "cli_interactions_pulls = cli_interactions_pulls[cli_interactions_pulls['created_by'].isin(cli_interactions_pulls_user_counts[cli_interactions_pulls_user_counts > cli_interactions_pulls_threshold].index)]\n",
    "\n",
    "#list all users that are in the top 20% of users in both datasets\n",
    "cli_interactions_users = cli_interactions['created_by'].unique()\n",
    "cli_interactions_pulls_users = cli_interactions_pulls['created_by'].unique()\n",
    "\n",
    "# print both lists\n",
    "print(\"Users in CLI Interactions:\")\n",
    "print(cli_interactions_users)\n",
    "print(\"Users in CLI Interactions Pulls:\")\n",
    "print(cli_interactions_pulls_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Data Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_daily_time_series(issues_activity, pulls_activity):\n",
    "    \n",
    "    # Combine issues and pulls data\n",
    "    issues_activity['data_source'] = 'issues'\n",
    "    pulls_activity['data_source'] = 'pulls'\n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_activity = pd.concat([issues_activity, pulls_activity], ignore_index=True)\n",
    "    \n",
    "    # Convert created_at to datetime if not already\n",
    "    combined_activity['created_at'] = pd.to_datetime(combined_activity['created_at'])\n",
    "    \n",
    "    # Extract date from created_at\n",
    "    combined_activity['year_month_day'] = combined_activity['created_at'].dt.to_period('W').astype(str)\n",
    "    \n",
    "    # Get unique interaction types\n",
    "    interaction_types = combined_activity['interaction_type'].unique()\n",
    "    \n",
    "    # Find the overall date range\n",
    "    min_date = combined_activity['year_month_day'].min()\n",
    "    max_date = combined_activity['year_month_day'].max()\n",
    "    \n",
    "    # Get unique users\n",
    "    unique_users = combined_activity['created_by'].unique()\n",
    "    \n",
    "    # Create a complete date range\n",
    "    complete_dates = pd.period_range(start=min_date, end=max_date, freq='W').astype(str)\n",
    "    \n",
    "    # Create a complete user-date grid\n",
    "    user_date_grid = []\n",
    "    for user in unique_users:\n",
    "        for date in complete_dates:\n",
    "            user_date_grid.append({\n",
    "                \"created_by\": user,\n",
    "                \"year_month_day\": date\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    complete_grid = pd.DataFrame(user_date_grid)\n",
    "    \n",
    "    # Compute daily interaction counts\n",
    "    daily_interaction_counts = combined_activity.groupby([\n",
    "        'created_by', 'year_month_day', 'interaction_type'\n",
    "    ]).size().reset_index(name='count')\n",
    "    \n",
    "    # Pivot to create columns for each interaction type\n",
    "    interaction_pivot = daily_interaction_counts.pivot_table(\n",
    "        index=['created_by', 'year_month_day'], \n",
    "        columns='interaction_type', \n",
    "        values='count', \n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Merge complete grid with interaction counts\n",
    "    df = pd.merge(\n",
    "        complete_grid, \n",
    "        interaction_pivot, \n",
    "        on=['created_by', 'year_month_day'], \n",
    "        how='left'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Compute source-specific activity\n",
    "    source_activity = combined_activity.groupby([\n",
    "        'created_by', 'year_month_day', 'data_source'\n",
    "    ]).size().reset_index(name='activity_count')\n",
    "    \n",
    "    source_pivot = source_activity.pivot_table(\n",
    "        index=['created_by', 'year_month_day'], \n",
    "        columns='data_source', \n",
    "        values='activity_count', \n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    source_pivot.columns.name = None\n",
    "    source_pivot = source_pivot.rename(columns={\n",
    "        'issues': 'total_activity_issues', \n",
    "        'pulls': 'total_activity_pulls'\n",
    "    })\n",
    "    \n",
    "    # Merge source activity\n",
    "    df = pd.merge(\n",
    "        df, \n",
    "        source_pivot, \n",
    "        on=['created_by', 'year_month_day'], \n",
    "        how='left'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Total activity\n",
    "    df['total_activity'] = df['total_activity_issues'] + df['total_activity_pulls']\n",
    "    \n",
    "    # Is active flag\n",
    "    df['is_active'] = (df['total_activity'] > 0).astype(int)\n",
    "    \n",
    "    # Create target variable (predicting inactivity in the next day)\n",
    "    df['target'] = (\n",
    "        df.groupby('created_by')['is_active'].shift(-1) == 0\n",
    "    ).fillna(0).astype(int)\n",
    "    \n",
    "    # Ensure all interaction type columns exist\n",
    "    for interaction in interaction_types:\n",
    "        if interaction not in df.columns:\n",
    "            df[interaction] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_user_specific_time_series(df):\n",
    "    # Find each user's first active day\n",
    "    user_first_active_day = df[df['total_activity'] > 0].groupby('created_by')['year_month_day'].min()\n",
    "    \n",
    "    # Filter DataFrame to start from user's first active day\n",
    "    filtered_df = df.merge(user_first_active_day, on='created_by', suffixes=('', '_first'))\n",
    "    filtered_df = filtered_df[filtered_df['year_month_day'] >= filtered_df['year_month_day_first']]\n",
    "\n",
    "    filtered_df= filtered_df.drop(columns=['year_month_day_first'])\n",
    "\n",
    "    \n",
    "    return filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "daily_time_series = create_comprehensive_daily_time_series(cli_interactions, cli_interactions_pulls)\n",
    "daily_time_series = create_user_specific_time_series(daily_time_series)\n",
    "#make this a xlsx file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- Feature Engineering ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(series):\n",
    "    \"\"\"Calculate Gini coefficient for a pandas Series or numpy array.\"\"\"\n",
    "    sorted_series = np.sort(series)\n",
    "    n = len(sorted_series)\n",
    "    if n == 0 or sorted_series.sum() == 0:\n",
    "        return 0.0\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (np.sum((2 * index - n - 1) * sorted_series)) / (n * np.sum(sorted_series))\n",
    "\n",
    "def calculate_interaction_entropy(row, interaction_columns):\n",
    "    \"\"\"Calculate entropy for interaction columns in a row.\"\"\"\n",
    "    interactions = row[interaction_columns].values.astype(float)\n",
    "    total = interactions.sum()\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    probs = interactions / total\n",
    "    non_zero_probs = probs[probs > 0]\n",
    "    if len(non_zero_probs) == 0:\n",
    "        return 0.0\n",
    "    return -np.sum(non_zero_probs * np.log2(non_zero_probs))\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Consolidated feature engineering function with all transformations.\"\"\"\n",
    "    # Identify interaction columns\n",
    "    interaction_columns = [\n",
    "    'assigned', 'closed', 'demilestoned', 'issue_comment', \n",
    "    'issue_creation', 'labeled', 'mentioned', 'milestoned', \n",
    "    'pr_comment', 'pr_commit', 'pr_creation', \n",
    "    'pr_review_approved', 'pr_review_commented', \n",
    "    'referenced', 'renamed', 'reopened', \n",
    "    'subscribed', 'transferred', 'unlabeled'\n",
    "]\n",
    "    \n",
    "    # 1. Row-level metrics\n",
    "    df['row_gini'] = df.apply(lambda row: calculate_gini(row[interaction_columns]), axis=1)\n",
    "    df['interaction_entropy'] = df.apply(calculate_interaction_entropy, axis=1, interaction_columns=interaction_columns)\n",
    "    \n",
    "    # 2. User-level statistics\n",
    "    user_agg = df.groupby('created_by').agg({\n",
    "        'total_activity': ['mean', 'median', 'max', 'std'],\n",
    "        'is_active': 'mean'\n",
    "    }).reset_index()\n",
    "    user_agg.columns = ['created_by', 'activity_mean', 'activity_median', \n",
    "                        'activity_max', 'activity_std', 'active_probability']\n",
    "    df = df.merge(user_agg, on='created_by', how='left')\n",
    "    \n",
    "    # 3. Activity-based features\n",
    "    df['relative_activity'] = df['total_activity'] / (df['activity_mean'] + 1e-10)\n",
    "    df['deviation_from_mean'] = df['total_activity'] - df['activity_mean']\n",
    "    df['activity_cv'] = df['activity_std'] / (df['activity_mean'] + 1e-10)\n",
    "    df['activity_zscore'] = (df['total_activity'] - df['activity_mean']) / (df['activity_std'] + 1e-10)\n",
    "    df['activity_gini'] = df.groupby('created_by')['total_activity'].transform(calculate_gini)\n",
    "    \n",
    "    # 4. Temporal features\n",
    "    for window in [3, 7, 14]:\n",
    "        # Rolling features\n",
    "        df[f'relative_rolling_{window}d'] = df.groupby('created_by')['relative_activity'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'deviation_rolling_{window}d'] = df.groupby('created_by')['deviation_from_mean'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'activity_rolling_{window}d_mean'] = df.groupby('created_by')['total_activity'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'activity_rolling_{window}d_std'] = df.groupby('created_by')['total_activity'].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).std())\n",
    "        \n",
    "        # Exponential smoothing\n",
    "        df[f'exp_smooth_{window}d'] = df.groupby('created_by')['total_activity'].transform(\n",
    "            lambda x: x.ewm(span=window, adjust=False).mean())\n",
    "    \n",
    "    # 5. Interaction features\n",
    "    for col in interaction_columns:\n",
    "        df[f'{col}_ratio'] = df[col] / (df['total_activity'] + 1e-10)\n",
    "    \n",
    "    # 6. Specialized metrics\n",
    "    df['pulls_to_issues_ratio'] = np.where(\n",
    "        df['total_activity_issues'] == 0,\n",
    "        10.0,\n",
    "        df['total_activity_pulls'] / df['total_activity_issues']\n",
    "    )\n",
    "    df['active_streak'] = df.groupby('created_by')['is_active'].transform(\n",
    "        lambda x: x * (x.groupby((x != x.shift()).cumsum()).cumcount() + 1)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_by</th>\n",
       "      <th>year_month_day</th>\n",
       "      <th>assigned</th>\n",
       "      <th>closed</th>\n",
       "      <th>demilestoned</th>\n",
       "      <th>issue_comment</th>\n",
       "      <th>issue_creation</th>\n",
       "      <th>labeled</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>milestoned</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_review_approved_ratio</th>\n",
       "      <th>pr_review_commented_ratio</th>\n",
       "      <th>referenced_ratio</th>\n",
       "      <th>renamed_ratio</th>\n",
       "      <th>reopened_ratio</th>\n",
       "      <th>subscribed_ratio</th>\n",
       "      <th>transferred_ratio</th>\n",
       "      <th>unlabeled_ratio</th>\n",
       "      <th>pulls_to_issues_ratio</th>\n",
       "      <th>active_streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hadley</td>\n",
       "      <td>2017-04-24/2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hadley</td>\n",
       "      <td>2017-05-01/2017-05-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hadley</td>\n",
       "      <td>2017-05-08/2017-05-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hadley</td>\n",
       "      <td>2017-05-15/2017-05-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hadley</td>\n",
       "      <td>2017-05-22/2017-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>romainfrancois</td>\n",
       "      <td>2025-01-27/2025-02-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>romainfrancois</td>\n",
       "      <td>2025-02-03/2025-02-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>romainfrancois</td>\n",
       "      <td>2025-02-10/2025-02-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>romainfrancois</td>\n",
       "      <td>2025-02-17/2025-02-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>romainfrancois</td>\n",
       "      <td>2025-02-24/2025-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2769 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          created_by         year_month_day  assigned  closed  demilestoned  \\\n",
       "0             hadley  2017-04-24/2017-04-30       0.0     0.0           0.0   \n",
       "1             hadley  2017-05-01/2017-05-07       0.0     0.0           0.0   \n",
       "2             hadley  2017-05-08/2017-05-14       0.0     0.0           0.0   \n",
       "3             hadley  2017-05-15/2017-05-21       0.0     0.0           0.0   \n",
       "4             hadley  2017-05-22/2017-05-28       0.0     0.0           0.0   \n",
       "...              ...                    ...       ...     ...           ...   \n",
       "2764  romainfrancois  2025-01-27/2025-02-02       0.0     0.0           0.0   \n",
       "2765  romainfrancois  2025-02-03/2025-02-09       0.0     0.0           0.0   \n",
       "2766  romainfrancois  2025-02-10/2025-02-16       0.0     0.0           0.0   \n",
       "2767  romainfrancois  2025-02-17/2025-02-23       0.0     0.0           0.0   \n",
       "2768  romainfrancois  2025-02-24/2025-03-02       0.0     0.0           0.0   \n",
       "\n",
       "      issue_comment  issue_creation  labeled  mentioned  milestoned  ...  \\\n",
       "0               1.0             2.0      0.0        0.0         0.0  ...   \n",
       "1               0.0             0.0      0.0        0.0         0.0  ...   \n",
       "2               0.0             0.0      0.0        0.0         0.0  ...   \n",
       "3               2.0             0.0      0.0        0.0         0.0  ...   \n",
       "4               0.0             0.0      0.0        0.0         0.0  ...   \n",
       "...             ...             ...      ...        ...         ...  ...   \n",
       "2764            0.0             0.0      0.0        0.0         0.0  ...   \n",
       "2765            0.0             0.0      0.0        0.0         0.0  ...   \n",
       "2766            0.0             0.0      0.0        0.0         0.0  ...   \n",
       "2767            0.0             0.0      0.0        0.0         0.0  ...   \n",
       "2768            0.0             0.0      0.0        0.0         0.0  ...   \n",
       "\n",
       "      pr_review_approved_ratio  pr_review_commented_ratio  referenced_ratio  \\\n",
       "0                          0.0                        0.0               0.0   \n",
       "1                          0.0                        0.0               0.0   \n",
       "2                          0.0                        0.0               0.0   \n",
       "3                          0.0                        0.0               0.0   \n",
       "4                          0.0                        0.0               0.0   \n",
       "...                        ...                        ...               ...   \n",
       "2764                       0.0                        0.0               0.0   \n",
       "2765                       0.0                        0.0               0.0   \n",
       "2766                       0.0                        0.0               0.0   \n",
       "2767                       0.0                        0.0               0.0   \n",
       "2768                       0.0                        0.0               0.0   \n",
       "\n",
       "      renamed_ratio  reopened_ratio  subscribed_ratio  transferred_ratio  \\\n",
       "0               0.0             0.0               0.0                0.0   \n",
       "1               0.0             0.0               0.0                0.0   \n",
       "2               0.0             0.0               0.0                0.0   \n",
       "3               0.0             0.0               0.0                0.0   \n",
       "4               0.0             0.0               0.0                0.0   \n",
       "...             ...             ...               ...                ...   \n",
       "2764            0.0             0.0               0.0                0.0   \n",
       "2765            0.0             0.0               0.0                0.0   \n",
       "2766            0.0             0.0               0.0                0.0   \n",
       "2767            0.0             0.0               0.0                0.0   \n",
       "2768            0.0             0.0               0.0                0.0   \n",
       "\n",
       "      unlabeled_ratio  pulls_to_issues_ratio  active_streak  \n",
       "0                 0.0                    0.0              1  \n",
       "1                 0.0                   10.0              0  \n",
       "2                 0.0                   10.0              0  \n",
       "3                 0.0                    0.0              1  \n",
       "4                 0.0                   10.0              0  \n",
       "...               ...                    ...            ...  \n",
       "2764              0.0                   10.0              0  \n",
       "2765              0.0                   10.0              0  \n",
       "2766              0.0                   10.0              0  \n",
       "2767              0.0                   10.0              0  \n",
       "2768              0.0                   10.0              0  \n",
       "\n",
       "[2769 rows x 74 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = engineer_features(daily_time_series)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepare data for machine learning models with user group handling\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        Prepared X, y, and user groups\n",
    "    \"\"\"\n",
    "    # Identify the user ID column (handle different possible column names)\n",
    "    user_id_col = 'user_id' if 'user_id' in df.columns else 'created_by'\n",
    "    \n",
    "    # Exclude columns\n",
    "    exclude_columns = [\n",
    "        'created_by', 'year_month_day', 'target', \n",
    "        'user_id', user_id_col\n",
    "    ]\n",
    "    \n",
    "    # Select features\n",
    "    feature_columns = [\n",
    "        col for col in df.columns \n",
    "        if col not in exclude_columns\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df['target']\n",
    "    user_groups = df[user_id_col]\n",
    "    \n",
    "    return X, y, user_groups\n",
    "\n",
    "def split_data_by_user(df):\n",
    "    \"\"\"\n",
    "    Split dataframe into individual user dataframes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with all users' data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of dataframes, one per user\n",
    "    \"\"\"\n",
    "    # Identify the user ID column\n",
    "    user_id_col = 'user_id' if 'user_id' in df.columns else 'created_by'\n",
    "    \n",
    "    user_dataframes = {\n",
    "        user: df[df[user_id_col] == user] \n",
    "        for user in df[user_id_col].unique()\n",
    "    }\n",
    "    \n",
    "    return user_dataframes\n",
    "\n",
    "def prepare_lstm_data(df):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        Prepared X, y for LSTM\n",
    "    \"\"\"\n",
    "    # Identify the user ID column\n",
    "    user_id_col = 'user_id' if 'user_id' in df.columns else 'created_by'\n",
    "    \n",
    "    # Group by user and create sequences\n",
    "    def create_sequences(group, look_back=7):\n",
    "        X, y = [], []\n",
    "        \n",
    "        # Exclude non-feature columns\n",
    "        feature_columns = [\n",
    "            col for col in group.columns \n",
    "            if col not in ['created_by', 'year_month_day', 'target', 'user_id', user_id_col]\n",
    "        ]\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(len(group) - look_back):\n",
    "            X.append(group[feature_columns].iloc[i:i+look_back].values)\n",
    "            y.append(group['target'].iloc[i+look_back])\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    # Prepare sequences for each user\n",
    "    sequences_data = df.groupby(user_id_col).apply(create_sequences)\n",
    "    \n",
    "    # Combine sequences\n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    for user_sequences in sequences_data:\n",
    "        X_sequences.extend(user_sequences[0])\n",
    "        y_sequences.extend(user_sequences[1])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X_sequences)\n",
    "    y = np.array(y_sequences)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate Random Forest Classifier\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Model performance metrics\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'  # Handle class imbalance\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Performance metrics\n",
    "    performance = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred),\n",
    "        'feature_importances': rf_model.feature_importances_\n",
    "    }\n",
    "    \n",
    "    # Feature Importance Analysis\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return performance\n",
    "\n",
    "\n",
    "def lstm_model(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate LSTM model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.array\n",
    "        Input sequences\n",
    "    y : np.array\n",
    "        Target variable\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Model performance metrics\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Build LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    \n",
    "    performance = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_parameter_tuning(X, y, user_groups=None):\n",
    "    \"\"\"\n",
    "    Perform comprehensive parameter tuning for XGBoost\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable\n",
    "    user_groups : pd.Series, optional\n",
    "        User group identifiers for group-based cross-validation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Tuning results and best model\n",
    "    \"\"\"\n",
    "    # Prepare cross-validation strategy\n",
    "    if user_groups is not None:\n",
    "        # Create a mapping of unique user groups to integers\n",
    "        unique_groups = user_groups.unique()\n",
    "        group_map = {group: i for i, group in enumerate(unique_groups)}\n",
    "        group_indices = np.array([group_map[g] for g in user_groups])\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Base XGBoost Classifier\n",
    "    base_model = xgb.XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Randomized Search Parameter Grid\n",
    "    random_search_params = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.5, 0.5),\n",
    "        'min_child_weight': randint(1, 7),\n",
    "        'gamma': uniform(0, 1)\n",
    "    }\n",
    "    \n",
    "    # Randomized Search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=random_search_params,\n",
    "        n_iter=100,  # Number of parameter settings sampled\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Fit Randomized Search\n",
    "    random_search.fit(X, y)\n",
    "    \n",
    "    # Grid Search with Refined Parameters\n",
    "    grid_search_params = {\n",
    "        'n_estimators': [\n",
    "            max(50, random_search.best_params_['n_estimators'] - 50),\n",
    "            random_search.best_params_['n_estimators'],\n",
    "            min(300, random_search.best_params_['n_estimators'] + 50)\n",
    "        ],\n",
    "        'max_depth': [\n",
    "            max(3, random_search.best_params_['max_depth'] - 1),\n",
    "            random_search.best_params_['max_depth'],\n",
    "            min(10, random_search.best_params_['max_depth'] + 1)\n",
    "        ],\n",
    "        'learning_rate': [\n",
    "            max(0.01, random_search.best_params_['learning_rate'] - 0.1),\n",
    "            random_search.best_params_['learning_rate'],\n",
    "            min(0.3, random_search.best_params_['learning_rate'] + 0.1)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=grid_search_params,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Fit Grid Search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Prepare results\n",
    "    tuning_results = {\n",
    "        'random_search_best_params': random_search.best_params_,\n",
    "        'random_search_best_score': random_search.best_score_,\n",
    "        'grid_search_best_params': grid_search.best_params_,\n",
    "        'grid_search_best_score': grid_search.best_score_,\n",
    "        'best_model': grid_search.best_estimator_\n",
    "    }\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n--- Randomized Search Best Parameters ---\")\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best Score: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Grid Search Best Parameters ---\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best Score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Feature Importance for Best Model\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    xgb.plot_importance(tuning_results['best_model'], height=0.8, max_num_features=10)\n",
    "    plt.title('Feature Importance for Best Model', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_model_feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return tuning_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis(df, X_train, X_test, y_train, y_test, best_model, feature_cols):\n",
    "    \"\"\"\n",
    "    Comprehensive model analysis function\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Original dataframe\n",
    "    X_train : pd.DataFrame\n",
    "        Training features\n",
    "    X_test : pd.DataFrame\n",
    "        Testing features\n",
    "    y_train : pd.Series\n",
    "        Training target\n",
    "    y_test : pd.Series\n",
    "        Testing target\n",
    "    best_model : XGBClassifier\n",
    "        Trained XGBoost model\n",
    "    feature_cols : list\n",
    "        List of feature column names\n",
    "    \"\"\"\n",
    "    # 1. Feature Importance Analysis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    xgb.plot_importance(best_model, height=0.8, max_num_features=len(feature_cols))\n",
    "    plt.title('Feature Importance (Weight)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_weight.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    xgb.plot_importance(best_model, height=0.8, importance_type='gain', max_num_features=len(feature_cols))\n",
    "    plt.title('Feature Importance (Gain)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_gain.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. SHAP Values for deeper insights\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Summary plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=feature_cols, show=False)\n",
    "    plt.title('SHAP Summary Plot', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Dependence plots for top features\n",
    "    top_features = [feature_cols[i] for i in np.argsort(np.abs(shap_values).mean(0))[-3:]]\n",
    "    for feature in top_features:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.dependence_plot(feature, shap_values, X_test, feature_names=feature_cols, show=False)\n",
    "        plt.title(f'SHAP Dependence Plot: {feature}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'shap_dependence_{feature}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # 3. Analysis of misclassifications\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    misclassified_idx = np.where(y_pred != y_test)[0]\n",
    "\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'true_label': y_test.iloc[misclassified_idx],\n",
    "        'predicted': y_pred[misclassified_idx],\n",
    "        'probability': best_model.predict_proba(X_test)[:, 1][misclassified_idx]\n",
    "    })\n",
    "\n",
    "    # Add feature values for misclassified instances\n",
    "    for feature in feature_cols:\n",
    "        misclassified_df[feature] = X_test.iloc[misclassified_idx][feature].values\n",
    "\n",
    "    # 4. False Negatives Analysis\n",
    "    false_negatives = misclassified_df[misclassified_df['true_label'] == 1]\n",
    "    print(f\"Number of false negatives: {len(false_negatives)}\")\n",
    "\n",
    "    if len(false_negatives) > 0:\n",
    "        print(\"\\nAverage feature values for false negatives:\")\n",
    "        for feature in feature_cols:\n",
    "            print(f\"{feature}: {false_negatives[feature].mean():.4f}\")\n",
    "        \n",
    "        print(\"\\nOverall average feature values:\")\n",
    "        for feature in feature_cols:\n",
    "            print(f\"{feature}: {X_test[feature].mean():.4f}\")\n",
    "\n",
    "    # 5. Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix (Counts)', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.savefig('confusion_matrix_counts.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1%', cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix (Percentages)', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.savefig('confusion_matrix_percent.png')\n",
    "    plt.close()\n",
    "\n",
    "    return misclassified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:20:18] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:20:25] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Randomized Search Best Parameters ---\n",
      "colsample_bytree: 0.6504391549083848\n",
      "gamma: 0.2848404943774676\n",
      "learning_rate: 0.021066084206359838\n",
      "max_depth: 3\n",
      "min_child_weight: 2\n",
      "n_estimators: 179\n",
      "subsample: 0.7644148053272926\n",
      "Best Score: 0.9417\n",
      "\n",
      "--- Grid Search Best Parameters ---\n",
      "learning_rate: 0.01\n",
      "max_depth: 3\n",
      "n_estimators: 229\n",
      "Best Score: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:20:26] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.52        73\n",
      "           1       0.92      0.96      0.94       479\n",
      "\n",
      "    accuracy                           0.89       552\n",
      "   macro avg       0.77      0.71      0.73       552\n",
      "weighted avg       0.88      0.89      0.88       552\n",
      "\n",
      "Accuracy: 0.8913043478260869\n",
      "ROC AUC Score: 0.7051505705379357\n",
      "Confusion Matrix:\n",
      "[[ 33  40]\n",
      " [ 20 459]]\n",
      "Feature Importances:\n",
      "\n",
      "Running Random Forest Model...\n",
      "Top 10 Most Important Features:\n",
      "                      feature  importance\n",
      "49             exp_smooth_14d    0.131981\n",
      "44              exp_smooth_7d    0.106251\n",
      "39              exp_smooth_3d    0.077743\n",
      "47  activity_rolling_14d_mean    0.060192\n",
      "48   activity_rolling_14d_std    0.051428\n",
      "35        relative_rolling_3d    0.042229\n",
      "45       relative_rolling_14d    0.038293\n",
      "38    activity_rolling_3d_std    0.038037\n",
      "37   activity_rolling_3d_mean    0.037877\n",
      "32                activity_cv    0.037643\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.60      0.53        73\n",
      "           1       0.94      0.90      0.92       479\n",
      "\n",
      "    accuracy                           0.86       552\n",
      "   macro avg       0.70      0.75      0.72       552\n",
      "weighted avg       0.88      0.86      0.87       552\n",
      "\n",
      "\n",
      "Running LSTM Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samut\\AppData\\Local\\Temp\\ipykernel_9824\\3104208907.py:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sequences_data = df.groupby(user_id_col).apply(create_sequences)\n",
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "LSTM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.46      0.56        95\n",
      "           1       0.89      0.96      0.92       443\n",
      "\n",
      "    accuracy                           0.87       538\n",
      "   macro avg       0.80      0.71      0.74       538\n",
      "weighted avg       0.86      0.87      0.86       538\n",
      "\n",
      "Number of false negatives: 20\n",
      "\n",
      "Average feature values for false negatives:\n",
      "assigned: 0.0000\n",
      "closed: 0.4500\n",
      "demilestoned: 0.0000\n",
      "issue_comment: 1.2000\n",
      "issue_creation: 0.4500\n",
      "labeled: 0.2000\n",
      "mentioned: 0.0000\n",
      "milestoned: 0.0000\n",
      "pr_comment: 0.2000\n",
      "pr_commit: 1.9000\n",
      "pr_creation: 0.0500\n",
      "pr_review_approved: 0.1000\n",
      "pr_review_commented: 0.4000\n",
      "referenced: 0.0000\n",
      "renamed: 0.0000\n",
      "reopened: 0.0500\n",
      "subscribed: 0.0000\n",
      "transferred: 0.0000\n",
      "unlabeled: 0.0000\n",
      "total_activity_issues: 2.3500\n",
      "total_activity_pulls: 2.6500\n",
      "total_activity: 5.0000\n",
      "is_active: 0.6000\n",
      "row_gini: 0.5450\n",
      "interaction_entropy: 0.5223\n",
      "activity_mean: 5.5039\n",
      "activity_median: 0.9000\n",
      "activity_max: 132.2000\n",
      "activity_std: 12.3616\n",
      "active_probability: 0.5071\n",
      "relative_activity: 1.8902\n",
      "deviation_from_mean: -0.5039\n",
      "activity_cv: 2.4435\n",
      "activity_zscore: 0.1680\n",
      "activity_gini: 0.8058\n",
      "relative_rolling_3d: 1.5807\n",
      "deviation_rolling_3d: 0.3294\n",
      "activity_rolling_3d_mean: 5.8333\n",
      "activity_rolling_3d_std: 5.9803\n",
      "exp_smooth_3d: 5.5285\n",
      "relative_rolling_7d: 1.4476\n",
      "deviation_rolling_7d: 0.4675\n",
      "activity_rolling_7d_mean: 5.9714\n",
      "activity_rolling_7d_std: 8.9160\n",
      "exp_smooth_7d: 5.5227\n",
      "relative_rolling_14d: 1.2838\n",
      "deviation_rolling_14d: -0.0182\n",
      "activity_rolling_14d_mean: 5.4857\n",
      "activity_rolling_14d_std: 9.3907\n",
      "exp_smooth_14d: 5.4521\n",
      "assigned_ratio: 0.0000\n",
      "closed_ratio: 0.0376\n",
      "demilestoned_ratio: 0.0000\n",
      "issue_comment_ratio: 0.2798\n",
      "issue_creation_ratio: 0.0505\n",
      "labeled_ratio: 0.0302\n",
      "mentioned_ratio: 0.0000\n",
      "milestoned_ratio: 0.0000\n",
      "pr_comment_ratio: 0.0143\n",
      "pr_commit_ratio: 0.1494\n",
      "pr_creation_ratio: 0.0012\n",
      "pr_review_approved_ratio: 0.0071\n",
      "pr_review_commented_ratio: 0.0286\n",
      "referenced_ratio: 0.0000\n",
      "renamed_ratio: 0.0000\n",
      "reopened_ratio: 0.0012\n",
      "subscribed_ratio: 0.0000\n",
      "transferred_ratio: 0.0000\n",
      "unlabeled_ratio: 0.0000\n",
      "pulls_to_issues_ratio: 5.4833\n",
      "active_streak: 1.5000\n",
      "\n",
      "Overall average feature values:\n",
      "assigned: 0.0018\n",
      "closed: 0.1685\n",
      "demilestoned: 0.0127\n",
      "issue_comment: 0.3152\n",
      "issue_creation: 0.0797\n",
      "labeled: 0.1051\n",
      "mentioned: 0.0163\n",
      "milestoned: 0.0543\n",
      "pr_comment: 0.0326\n",
      "pr_commit: 0.3370\n",
      "pr_creation: 0.0870\n",
      "pr_review_approved: 0.0072\n",
      "pr_review_commented: 0.0507\n",
      "referenced: 0.0362\n",
      "renamed: 0.0054\n",
      "reopened: 0.0091\n",
      "subscribed: 0.0163\n",
      "transferred: 0.0036\n",
      "unlabeled: 0.0000\n",
      "total_activity_issues: 0.8243\n",
      "total_activity_pulls: 0.5145\n",
      "total_activity: 1.3388\n",
      "is_active: 0.1431\n",
      "row_gini: 0.1259\n",
      "interaction_entropy: 0.1598\n",
      "activity_mean: 1.2869\n",
      "activity_median: 0.1739\n",
      "activity_max: 40.2609\n",
      "activity_std: 3.5720\n",
      "active_probability: 0.1526\n",
      "relative_activity: 1.1925\n",
      "deviation_from_mean: 0.0518\n",
      "activity_cv: 5.8248\n",
      "activity_zscore: 0.0228\n",
      "activity_gini: 0.9314\n",
      "relative_rolling_3d: 1.1351\n",
      "deviation_rolling_3d: -0.0243\n",
      "activity_rolling_3d_mean: 1.2627\n",
      "activity_rolling_3d_std: 1.3485\n",
      "exp_smooth_3d: 1.2344\n",
      "relative_rolling_7d: 1.2004\n",
      "deviation_rolling_7d: -0.1417\n",
      "activity_rolling_7d_mean: 1.1452\n",
      "activity_rolling_7d_std: 1.6045\n",
      "exp_smooth_7d: 1.1896\n",
      "relative_rolling_14d: 1.2665\n",
      "deviation_rolling_14d: -0.1666\n",
      "activity_rolling_14d_mean: 1.1203\n",
      "activity_rolling_14d_std: 1.8555\n",
      "exp_smooth_14d: 1.2244\n",
      "assigned_ratio: 0.0002\n",
      "closed_ratio: 0.0117\n",
      "demilestoned_ratio: 0.0004\n",
      "issue_comment_ratio: 0.0501\n",
      "issue_creation_ratio: 0.0130\n",
      "labeled_ratio: 0.0097\n",
      "mentioned_ratio: 0.0033\n",
      "milestoned_ratio: 0.0018\n",
      "pr_comment_ratio: 0.0015\n",
      "pr_commit_ratio: 0.0292\n",
      "pr_creation_ratio: 0.0106\n",
      "pr_review_approved_ratio: 0.0004\n",
      "pr_review_commented_ratio: 0.0024\n",
      "referenced_ratio: 0.0031\n",
      "renamed_ratio: 0.0010\n",
      "reopened_ratio: 0.0009\n",
      "subscribed_ratio: 0.0033\n",
      "transferred_ratio: 0.0005\n",
      "unlabeled_ratio: 0.0000\n",
      "pulls_to_issues_ratio: 8.9422\n",
      "active_streak: 0.4855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_search_best_params': {'colsample_bytree': 0.6504391549083848,\n",
       "  'gamma': 0.2848404943774676,\n",
       "  'learning_rate': 0.021066084206359838,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 179,\n",
       "  'subsample': 0.7644148053272926},\n",
       " 'random_search_best_score': 0.9416974678274469,\n",
       " 'grid_search_best_params': {'learning_rate': 0.01,\n",
       "  'max_depth': 3,\n",
       "  'n_estimators': 229},\n",
       " 'grid_search_best_score': 0.9406192843842259,\n",
       " 'best_model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=229,\n",
       "               n_jobs=None, num_parallel_tree=None, random_state=42, ...)}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def main(df):\n",
    "    # Prepare data\n",
    "    X, y, user_groups = prepare_data(df)\n",
    "    \n",
    "    # Perform XGBoost Parameter Tuning\n",
    "    tuning_results = xgboost_parameter_tuning(X, y, user_groups)\n",
    "    \n",
    "    # Use the best model for further analysis\n",
    "    best_model = tuning_results['best_model']\n",
    "    \n",
    "    # Split data for final model evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit best model\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(\"Best Model Performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Feature Importances:\")\n",
    "    \n",
    "\n",
    "\n",
    "     # Continue with other models (optional)\n",
    "    # Random Forest Model\n",
    "    print(\"\\nRunning Random Forest Model...\")\n",
    "    rf_results = random_forest_model(X, y)\n",
    "    print(\"Random Forest Results:\")\n",
    "    print(rf_results['classification_report'])\n",
    "    \n",
    "    # LSTM Model\n",
    "    print(\"\\nRunning LSTM Model...\")\n",
    "    X_lstm, y_lstm = prepare_lstm_data(df)\n",
    "    lstm_results = lstm_model(X_lstm, y_lstm)\n",
    "    print(\"LSTM Results:\")\n",
    "    print(lstm_results['classification_report'])\n",
    "    \n",
    "    \n",
    "    # Perform Model Analysis with Best Model\n",
    "    feature_cols = list(X.columns)\n",
    "    misclassified_df = model_analysis(\n",
    "        df, \n",
    "        X_train, \n",
    "        X_test, \n",
    "        y_train, \n",
    "        y_test, \n",
    "        best_model, \n",
    "        feature_cols\n",
    "    )\n",
    "    \n",
    "    return tuning_results\n",
    "\n",
    "\n",
    "main(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year_month'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'year_month'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data\u001b[38;5;241m=\u001b[39m all_activity\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear_month\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mto_timestamp()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sort Data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_by\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'year_month'"
     ]
    }
   ],
   "source": [
    "data= all_activity\n",
    "data[\"year_month\"] = data[\"year_month\"].dt.to_timestamp()\n",
    "\n",
    "# Sort Data\n",
    "data = data.sort_values(by=[\"created_by\", \"year_month\"])\n",
    "\n",
    "# Create Lag and Rolling Features\n",
    "data[\"prev_month_activity\"] = data.groupby(\"created_by\")[\"count\"].shift(1)\n",
    "data[\"rolling_3m_avg\"] = data.groupby(\"created_by\")[\"count\"].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "data[\"month\"] = data[\"year_month\"].dt.month  # Add month as a feature\n",
    "\n",
    "# Target Variable: Next Month's Activity\n",
    "data[\"next_month_activity\"] = data.groupby(\"created_by\")[\"count\"].shift(-1)\n",
    "\n",
    "# Drop NaN values (last months won't have next month activity)\n",
    "data = data.dropna()\n",
    "\n",
    "# Define Features & Target\n",
    "features = [\"prev_month_activity\", \"rolling_3m_avg\", \"month\"]\n",
    "X = data[features]\n",
    "y = data[\"next_month_activity\"]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Models\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"XGBoost MAE: {mae_xgb}\")\n",
    "print(f\"Random Forest MAE: {mae_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for modeling\n",
    "feature_cols = [\n",
    "    'past_4_weeks_issues',\n",
    "    'past_4_weeks_pulls',\n",
    "    'activity_mix_pulls',\n",
    "    'activity_mix_issues',\n",
    "    'active_streak',\n",
    "    'exp_smooth_activity',\n",
    "    'avg_activity',\n",
    "    'activity_burst',\n",
    "    'issue_to_pull_ratio'\n",
    "]\n",
    "\n",
    "# Sample split code (for reference)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove NaN values that might have been introduced\n",
    "df_model = df.dropna(subset=feature_cols + ['target'])\n",
    "\n",
    "# Train-test split\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: target\n",
      "1    0.907399\n",
      "0    0.092601\n",
      "Name: proportion, dtype: float64\n",
      "Training set size: 2676\n",
      "Validation set size: 892\n",
      "Test set size: 892\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have a valid dataset\n",
    "df_model = df.dropna(subset=feature_cols + ['target'])\n",
    "\n",
    "# Print distribution of target variable\n",
    "print(f\"Target distribution: {df_model['target'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Split the data\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['target']\n",
    "\n",
    "# Create a stratified train/validation/test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:13:16] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Basic Model Validation Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59        83\n",
      "           1       0.95      0.97      0.96       809\n",
      "\n",
      "    accuracy                           0.93       892\n",
      "   macro avg       0.79      0.76      0.78       892\n",
      "weighted avg       0.92      0.93      0.93       892\n",
      "\n",
      "ROC AUC: 0.8770\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "--- Grid Search Results ---\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
      "Best cross-validation score: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:13:31] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a basic XGBoost model\n",
    "basic_model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "basic_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the basic model\n",
    "val_preds = basic_model.predict(X_val)\n",
    "val_probs = basic_model.predict_proba(X_val)[:, 1]\n",
    "print(\"\\n--- Basic Model Validation Results ---\")\n",
    "print(classification_report(y_val, val_preds))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, val_probs):.4f}\")\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "features = X_train.columns\n",
    "importances = basic_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'scale_pos_weight': [1, sum(y_train == 0) / sum(y_train == 1)]  # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"\\n--- Grid Search Results ---\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model Validation Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.52      0.59        83\n",
      "           1       0.95      0.98      0.96       809\n",
      "\n",
      "    accuracy                           0.93       892\n",
      "   macro avg       0.82      0.75      0.78       892\n",
      "weighted avg       0.93      0.93      0.93       892\n",
      "\n",
      "ROC AUC: 0.9012\n",
      "\n",
      "--- Final Test Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.48      0.58        83\n",
      "           1       0.95      0.98      0.96       809\n",
      "\n",
      "    accuracy                           0.93       892\n",
      "   macro avg       0.84      0.73      0.77       892\n",
      "weighted avg       0.93      0.93      0.93       892\n",
      "\n",
      "ROC AUC: 0.9063\n",
      "\n",
      "Optimal threshold for F1 score: 0.3951\n",
      "\n",
      "--- Results with Optimal Threshold ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.36      0.51        83\n",
      "           1       0.94      1.00      0.97       809\n",
      "\n",
      "    accuracy                           0.94       892\n",
      "   macro avg       0.91      0.68      0.74       892\n",
      "weighted avg       0.93      0.94      0.92       892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on validation set\n",
    "val_preds_best = best_model.predict(X_val)\n",
    "val_probs_best = best_model.predict_proba(X_val)[:, 1]\n",
    "print(\"\\n--- Best Model Validation Results ---\")\n",
    "print(classification_report(y_val, val_preds_best))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, val_probs_best):.4f}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "test_preds = best_model.predict(X_test)\n",
    "test_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "print(\"\\n--- Final Test Results ---\")\n",
    "print(classification_report(y_test, test_preds))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, test_probs):.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Precision-Recall curve for threshold selection\n",
    "plt.figure(figsize=(8, 6))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, test_probs)\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "plt.savefig('precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Find optimal threshold based on F1 score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"\\nOptimal threshold for F1 score: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Apply optimal threshold\n",
    "optimal_preds = (test_probs >= optimal_threshold).astype(int)\n",
    "print(\"\\n--- Results with Optimal Threshold ---\")\n",
    "print(classification_report(y_test, optimal_preds))\n",
    "\n",
    "# Save the model for future predictions\n",
    "best_model.save_model('xgboost_user_activity_prediction.json')\n",
    "\n",
    "# Example of how to use the model for predictions on new data\n",
    "def predict_user_inactivity(user_data, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predicts whether users will be inactive next week\n",
    "    \n",
    "    Parameters:\n",
    "    user_data (DataFrame): DataFrame with feature columns\n",
    "    model: Trained XGBoost model\n",
    "    threshold: Classification threshold\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with prediction results\n",
    "    \"\"\"\n",
    "    # Ensure user_data has all required features\n",
    "    missing_features = set(feature_cols) - set(user_data.columns)\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing features in input data: {missing_features}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    probs = model.predict_proba(user_data[feature_cols])[:, 1]\n",
    "    predictions = (probs >= threshold).astype(int)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = user_data[['created_by', 'week_start']].copy()\n",
    "    results['inactive_probability'] = probs\n",
    "    results['predicted_inactive'] = predictions\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance Analysis: Tells you which features are driving predictions\n",
    "\n",
    "Both weight-based and gain-based importance visualizations\n",
    "SHAP values for more accurate feature contribution analysis\n",
    "\n",
    "\n",
    "Misclassification Analysis: Deep dive into where the model fails\n",
    "\n",
    "Detailed breakdown of false negatives (users we failed to predict would become inactive)\n",
    "Comparison between misclassified cases and overall averages\n",
    "\n",
    "\n",
    "Individual User Analysis: The analyze_user_predictions() function\n",
    "\n",
    "Time series visualization of specific users' activity\n",
    "Shows when the model predicted correctly vs. incorrectly\n",
    "Perfect for understanding high-profile users like 'hadley', 'gaborcsardi', etc.\n",
    "\n",
    "\n",
    "Insightful Explanations: The explain_individual_prediction() function\n",
    "\n",
    "Generates readable explanations for any prediction\n",
    "Identifies the top factors contributing to each prediction\n",
    "Perfect for explaining to stakeholders why a particular prediction was made\n",
    "\n",
    "im working of feature diagnostics and more data colling about the users watches and stars\n",
    "\n",
    "I working on more data collection too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false negatives: 15\n",
      "\n",
      "Average feature values for false negatives:\n",
      "past_4_weeks_issues: 16.0000\n",
      "past_4_weeks_pulls: 6.6667\n",
      "activity_mix_pulls: 0.0000\n",
      "activity_mix_issues: 0.7333\n",
      "active_streak: 2.3333\n",
      "exp_smooth_activity: 4.6745\n",
      "avg_activity: 5.6946\n",
      "activity_burst: -0.7973\n",
      "issue_to_pull_ratio: 10.0000\n",
      "\n",
      "Overall average feature values:\n",
      "past_4_weeks_issues: 1.8531\n",
      "past_4_weeks_pulls: 0.9137\n",
      "activity_mix_pulls: 0.0240\n",
      "activity_mix_issues: 0.0747\n",
      "active_streak: 0.3587\n",
      "exp_smooth_activity: 0.6722\n",
      "avg_activity: 0.7475\n",
      "activity_burst: -0.1299\n",
      "issue_to_pull_ratio: 9.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming 'best_model' is your trained XGBoost model\n",
    "# and X_test, y_test are your test data\n",
    "\n",
    "# 1. Feature Importance Analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(best_model, height=0.8, max_num_features=len(feature_cols))\n",
    "plt.title('Feature Importance (Weight)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_weight.png')\n",
    "plt.close()\n",
    "\n",
    "# Gain-based importance (how much each feature improves the model)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(best_model, height=0.8, importance_type='gain', max_num_features=len(feature_cols))\n",
    "plt.title('Feature Importance (Gain)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_gain.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. SHAP Values for deeper insights\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_cols, show=False)\n",
    "plt.title('SHAP Summary Plot', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_summary.png')\n",
    "plt.close()\n",
    "\n",
    "# Dependence plots for top features\n",
    "top_features = [feature_cols[i] for i in np.argsort(np.abs(shap_values).mean(0))[-3:]]\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.dependence_plot(feature, shap_values, X_test, feature_names=feature_cols, show=False)\n",
    "    plt.title(f'SHAP Dependence Plot: {feature}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'shap_dependence_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Analysis of misclassifications\n",
    "y_pred = best_model.predict(X_test)\n",
    "misclassified_idx = np.where(y_pred != y_test)[0]\n",
    "\n",
    "misclassified_df = pd.DataFrame({\n",
    "    'true_label': y_test.iloc[misclassified_idx],\n",
    "    'predicted': y_pred[misclassified_idx],\n",
    "    'probability': best_model.predict_proba(X_test.iloc[misclassified_idx])[:, 1]\n",
    "})\n",
    "\n",
    "# Add feature values for misclassified instances\n",
    "for feature in feature_cols:\n",
    "    misclassified_df[feature] = X_test.iloc[misclassified_idx][feature].values\n",
    "\n",
    "# Add user identifiers if available in the test set\n",
    "if 'created_by' in df_model.columns:\n",
    "    misclassified_df['user'] = df_model.iloc[X_test.index[misclassified_idx]]['created_by'].values\n",
    "\n",
    "# 4. Analysis of false negatives (users we predicted would be active but weren't)\n",
    "false_negatives = misclassified_df[misclassified_df['true_label'] == 1]\n",
    "print(f\"Number of false negatives: {len(false_negatives)}\")\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    # Print average feature values for false negatives\n",
    "    print(\"\\nAverage feature values for false negatives:\")\n",
    "    for feature in feature_cols:\n",
    "        print(f\"{feature}: {false_negatives[feature].mean():.4f}\")\n",
    "    \n",
    "    # Compare with overall average\n",
    "    print(\"\\nOverall average feature values:\")\n",
    "    for feature in feature_cols:\n",
    "        print(f\"{feature}: {X_test[feature].mean():.4f}\")\n",
    "\n",
    "# 5. Confusion matrix with percentages\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Counts)', fontsize=16)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.savefig('confusion_matrix_counts.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_percent, annot=True, fmt='.1%', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Percentages)', fontsize=16)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.savefig('confusion_matrix_percent.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. Individual user prediction analysis\n",
    "def analyze_user_predictions(user_id, df=df_model, model=best_model, features=feature_cols):\n",
    "    \"\"\"Analyze predictions for a specific user over time\"\"\"\n",
    "    user_data = df[df['created_by'] == user_id].copy()\n",
    "    \n",
    "    if len(user_data) == 0:\n",
    "        return \"User not found in dataset\"\n",
    "    \n",
    "    # Make predictions\n",
    "    user_data['predicted_prob'] = model.predict_proba(user_data[features])[:, 1]\n",
    "    user_data['predicted_inactive'] = model.predict(user_data[features])\n",
    "    \n",
    "    # Create time series plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot activity and prediction\n",
    "    plt.plot(user_data['week_start'], user_data['total_activity'], \n",
    "             label='Actual Activity', marker='o', color='blue')\n",
    "    \n",
    "    # Add target (actual inactivity next week)\n",
    "    inactive_weeks = user_data[user_data['target'] == 1]['week_start']\n",
    "    if len(inactive_weeks) > 0:\n",
    "        plt.scatter(inactive_weeks, \n",
    "                   [0] * len(inactive_weeks), \n",
    "                   color='red', s=100, marker='x',\n",
    "                   label='Actually Inactive Next Week')\n",
    "    \n",
    "    # Add predictions\n",
    "    predicted_inactive = user_data[user_data['predicted_inactive'] == 1]['week_start']\n",
    "    if len(predicted_inactive) > 0:\n",
    "        plt.scatter(predicted_inactive, \n",
    "                   [0] * len(predicted_inactive), \n",
    "                   color='orange', s=100, marker='+', \n",
    "                   label='Predicted Inactive Next Week')\n",
    "    \n",
    "    # Add prediction probability as a secondary axis\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.plot(user_data['week_start'], user_data['predicted_prob'], \n",
    "             color='green', linestyle='--', label='Inactivity Probability')\n",
    "    ax2.set_ylabel('Inactivity Probability', color='green', fontsize=12)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.title(f'User Activity and Inactivity Predictions: {user_id}', fontsize=16)\n",
    "    plt.xlabel('Week', fontsize=12)\n",
    "    plt.ylabel('Activity Count', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines1, labels1 = plt.gca().get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'user_prediction_{user_id}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return user_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'week_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'week_start'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Analyze predictions for specific users\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadley\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaborcsardi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjennybc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlionel-\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43manalyze_user_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 7. Create a dashboard of key insights\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_insight_dashboard\u001b[39m(model, X_test, y_test, feature_cols):\n",
      "Cell \u001b[1;32mIn[20], line 111\u001b[0m, in \u001b[0;36manalyze_user_predictions\u001b[1;34m(user_id, df, model, features)\u001b[0m\n\u001b[0;32m    108\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Plot activity and prediction\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43muser_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweek_start\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, user_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_activity\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    112\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Activity\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Add target (actual inactivity next week)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m inactive_weeks \u001b[38;5;241m=\u001b[39m user_data[user_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek_start\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\samut\\anaconda3\\envs\\CS485\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'week_start'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Example: Analyze predictions for specific users\n",
    "for user in ['hadley', 'gaborcsardi', 'jennybc', 'lionel-']:\n",
    "    analyze_user_predictions(user)\n",
    "\n",
    "# 7. Create a dashboard of key insights\n",
    "def create_insight_dashboard(model, X_test, y_test, feature_cols):\n",
    "    \"\"\"Create a comprehensive dashboard of model insights\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    grid = plt.GridSpec(4, 2, figure=fig)\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix', fontsize=14)\n",
    "    ax1.set_ylabel('True Label', fontsize=12)\n",
    "    ax1.set_xlabel('Predicted Label', fontsize=12)\n",
    "    \n",
    "    # 2. Feature Importance\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    ax2.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    ax2.set_yticks(range(len(indices)))\n",
    "    ax2.set_yticklabels([feature_cols[i] for i in indices])\n",
    "    ax2.set_title('Feature Importance', fontsize=14)\n",
    "    ax2.set_xlabel('Relative Importance', fontsize=12)\n",
    "    \n",
    "    # 3. Precision-Recall Curve\n",
    "    ax3 = fig.add_subplot(grid[1, 0])\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precs, recs, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    ax3.plot(recs, precs, 'b-', linewidth=2)\n",
    "    ax3.set_title('Precision-Recall Curve', fontsize=14)\n",
    "    ax3.set_xlabel('Recall', fontsize=12)\n",
    "    ax3.set_ylabel('Precision', fontsize=12)\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # 4. ROC Curve\n",
    "    ax4 = fig.add_subplot(grid[1, 1])\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax4.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {roc_auc:.3f}')\n",
    "    ax4.plot([0, 1], [0, 1], 'k--')\n",
    "    ax4.set_title('ROC Curve', fontsize=14)\n",
    "    ax4.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax4.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax4.legend(loc='lower right')\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    # 5. Feature Distribution: Active vs Inactive\n",
    "    features_to_plot = [feature_cols[i] for i in indices[:4]]  # Top 4 features\n",
    "    for i, feature in enumerate(features_to_plot):\n",
    "        ax = fig.add_subplot(grid[2 + i//2, i%2])\n",
    "        active_vals = X_test[y_test == 0][feature]\n",
    "        inactive_vals = X_test[y_test == 1][feature]\n",
    "        sns.kdeplot(active_vals, ax=ax, label='Active Users', fill=True, alpha=0.3)\n",
    "        sns.kdeplot(inactive_vals, ax=ax, label='Inactive Users', fill=True, alpha=0.3)\n",
    "        ax.set_title(f'Distribution of {feature}', fontsize=14)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_insights_dashboard.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "create_insight_dashboard(best_model, X_test, y_test, feature_cols)\n",
    "\n",
    "# 8. Create explanations for individual predictions\n",
    "def explain_individual_prediction(user_id, week, model, feature_cols):\n",
    "    \"\"\"Generate a human-readable explanation for a specific prediction\"\"\"\n",
    "    # Get user data for the specified week\n",
    "    user_week_data = df_model[(df_model['created_by'] == user_id) & \n",
    "                             (df_model['week_start'] == pd.to_datetime(week))]\n",
    "    \n",
    "    if len(user_week_data) == 0:\n",
    "        return f\"No data found for user {user_id} in week {week}\"\n",
    "    \n",
    "    # Get features for the prediction\n",
    "    features = user_week_data[feature_cols].iloc[0]\n",
    "    \n",
    "    # Make prediction\n",
    "    prob = model.predict_proba(features.values.reshape(1, -1))[0, 1]\n",
    "    prediction = \"INACTIVE\" if prob > 0.5 else \"ACTIVE\"\n",
    "    \n",
    "    # Get SHAP values for explanation\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(features.values.reshape(1, -1))[0]\n",
    "    \n",
    "    # Get top 3 contributing features\n",
    "    feature_importance = list(zip(feature_cols, shap_values))\n",
    "    feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    top_features = feature_importance[:3]\n",
    "    \n",
    "    # Build explanation\n",
    "    explanation = f\"User {user_id} is predicted to be {prediction} next week with {prob:.1%} probability.\\n\\n\"\n",
    "    explanation += \"Top contributing factors:\\n\"\n",
    "    \n",
    "    for feature, value in top_features:\n",
    "        feature_value = features[feature]\n",
    "        if value > 0:\n",
    "            explanation += f\"- {feature} = {feature_value:.2f} (increases likelihood of inactivity)\\n\"\n",
    "        else:\n",
    "            explanation += f\"- {feature} = {feature_value:.2f} (decreases likelihood of inactivity)\\n\"\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "# Example usage\n",
    "print(explain_individual_prediction('hadley', '2023-01-01', best_model, feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MichaelChirico', 'gaborcsardi', 'hadley', 'jennybc', 'krlmlr',\n",
       "       'lionel-', 'olivroy', 'romainfrancois', 'rundel', 'salim-b'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = df['created_by'].unique()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Rate Limit: (4744, 5000)\n",
      "Fetching data for MichaelChirico...\n",
      "Fetching data for gaborcsardi...\n",
      "Fetching data for hadley...\n",
      "Fetching data for jennybc...\n",
      "Fetching data for krlmlr...\n",
      "Fetching data for lionel-...\n",
      "Fetching data for olivroy...\n",
      "Fetching data for romainfrancois...\n",
      "Fetching data for rundel...\n",
      "Fetching data for salim-b...\n",
      "User engagement data collected and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Authenticate\n",
    "secret = \"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\"\n",
    "g = Github(secret)\n",
    "\n",
    "def fetch_user_events(username, event_type):\n",
    "    \"\"\"Fetch user events from GitHub and filter by event type (handles pagination).\"\"\"\n",
    "    try:\n",
    "        user = g.get_user(username)\n",
    "        events = user.get_events()  # Gets public events (pagination happens here)\n",
    "        \n",
    "        # Collect filtered events\n",
    "        filtered_events = []\n",
    "        for event in events:\n",
    "            if event.type == event_type:\n",
    "                filtered_events.append(event)\n",
    "            if len(filtered_events) >= 100:  # Limit to avoid API overuse\n",
    "                break\n",
    "        \n",
    "        return filtered_events\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching events for {username}: {e}\")\n",
    "        return []\n",
    "\n",
    "def count_weekly_events(events):\n",
    "    \"\"\"Count weekly occurrences of events.\"\"\"\n",
    "    weekly_counts = {}\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    for event in events:\n",
    "        event_date = event.created_at\n",
    "        week = (now - event_date).days // 7\n",
    "        weekly_counts[week] = weekly_counts.get(week, 0) + 1\n",
    "        \n",
    "    return weekly_counts\n",
    "\n",
    "def collect_user_engagement(username):\n",
    "    \"\"\"Collect weekly engagement metrics for a user.\"\"\"\n",
    "    star_events = fetch_user_events(username, \"StarEvent\")  # Starring a repo\n",
    "    fork_events = fetch_user_events(username, \"ForkEvent\")  # Forking a repo\n",
    "    watch_events = fetch_user_events(username, \"WatchEvent\")  # Watching a repo (deprecated, may be empty)\n",
    "\n",
    "    return {\n",
    "        \"weekly_stars\": count_weekly_events(star_events),\n",
    "        \"weekly_forks\": count_weekly_events(fork_events),\n",
    "        \"weekly_watches\": count_weekly_events(watch_events),\n",
    "    }\n",
    "\n",
    "# Check rate-limiting before running\n",
    "print(f\"API Rate Limit: {g.rate_limiting}\")\n",
    "\n",
    "# Load your existing dataframe with users\n",
    "users = df['created_by'].unique()\n",
    "\n",
    "# Collect engagement data for each user\n",
    "engagement_data = {}\n",
    "for user in users:\n",
    "    print(f\"Fetching data for {user}...\")\n",
    "    engagement_data[user] = collect_user_engagement(user)\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "engagement_df = pd.DataFrame(engagement_data).T\n",
    "engagement_df.to_csv(\"user_engagement_data.csv\", index=True)\n",
    "\n",
    "print(\"User engagement data collected and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekly_stars</th>\n",
       "      <th>weekly_forks</th>\n",
       "      <th>weekly_watches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MichaelChirico</th>\n",
       "      <td>{}</td>\n",
       "      <td>{0: 7}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaborcsardi</th>\n",
       "      <td>{}</td>\n",
       "      <td>{0: 1}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadley</th>\n",
       "      <td>{}</td>\n",
       "      <td>{2: 3}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jennybc</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krlmlr</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lionel-</th>\n",
       "      <td>{}</td>\n",
       "      <td>{0: 2}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olivroy</th>\n",
       "      <td>{}</td>\n",
       "      <td>{2: 4}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romainfrancois</th>\n",
       "      <td>{}</td>\n",
       "      <td>{3: 1}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rundel</th>\n",
       "      <td>{}</td>\n",
       "      <td>{3: 1}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salim-b</th>\n",
       "      <td>{}</td>\n",
       "      <td>{0: 5, 1: 3, 2: 2, 3: 2}</td>\n",
       "      <td>{0: 2, 1: 4, 2: 3, 3: 17}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               weekly_stars              weekly_forks  \\\n",
       "MichaelChirico           {}                    {0: 7}   \n",
       "gaborcsardi              {}                    {0: 1}   \n",
       "hadley                   {}                    {2: 3}   \n",
       "jennybc                  {}                        {}   \n",
       "krlmlr                   {}                        {}   \n",
       "lionel-                  {}                    {0: 2}   \n",
       "olivroy                  {}                    {2: 4}   \n",
       "romainfrancois           {}                    {3: 1}   \n",
       "rundel                   {}                    {3: 1}   \n",
       "salim-b                  {}  {0: 5, 1: 3, 2: 2, 3: 2}   \n",
       "\n",
       "                           weekly_watches  \n",
       "MichaelChirico                         {}  \n",
       "gaborcsardi                            {}  \n",
       "hadley                                 {}  \n",
       "jennybc                                {}  \n",
       "krlmlr                             {1: 1}  \n",
       "lionel-                                {}  \n",
       "olivroy                                {}  \n",
       "romainfrancois                         {}  \n",
       "rundel                                 {}  \n",
       "salim-b         {0: 2, 1: 4, 2: 3, 3: 17}  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engagement_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS485",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
